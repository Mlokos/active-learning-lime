{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52bdc712-1088-4c46-84ff-bd2636f09bc5",
   "metadata": {},
   "source": [
    "# **Uczenie Maszynowe - LAB03 - LIME**\n",
    "\n",
    "Przygotowali: Arkadiusz Pajor i Michał Sokół\n",
    "\n",
    "Ten notebook jest wprowadzeniem w zagadnienie Interpretowalnego Uczenia Aktywnego (ang. Interpretable Active Learning).\n",
    "\n",
    "Slajdy z prezentacji znajdują się w załączonych materiałach.\n",
    "\n",
    "Biblioteka LIME: https://github.com/marcotcr/lime (Dokumentacja API: https://lime-ml.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922d901d-fe50-414a-b6bd-76e2744b6c71",
   "metadata": {},
   "source": [
    "# **Wprowadzenie - pakiety**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaff1779-05b1-4afc-9c2f-46e5368b2d3d",
   "metadata": {},
   "source": [
    "Niezbędne pakiety i moduły na potrzeby wprowadzenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465d8a9e-65b9-4307-815e-838b38c21ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from lime import lime_image\n",
    "from PIL import Image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2776a-5524-475b-839c-aa654a22930c",
   "metadata": {},
   "source": [
    "# Wprowadzenie - funkcje pomocnicze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b18044a-54e1-492d-bb9f-248912dcd9a0",
   "metadata": {},
   "source": [
    "Funkcja do wczytywania wskazanego obrazka oraz konwersji do palety RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f99bfe1-2d3c-4b4a-9b3b-a50c9067c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef56eddd-8f65-4d9f-bfae-3f1a0ec1e687",
   "metadata": {},
   "source": [
    "Funkcja do przekształcania obrazka (zwróconego przez funkcję `get_image`) w tensor, akceptowalny na wejściu sieci neronowej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29cc52-1b17-4a25-969a-2d598127084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_tensor(img):    \n",
    "    transformer = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225])\n",
    "    ])  \n",
    "    return transformer(img).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef20acb-18e6-4dbc-b426-9ad809d069b0",
   "metadata": {},
   "source": [
    "Funkcja używana przez LIME, przyjuje na wejściu zbiór obrazków, a zwraca prawdopodobieństwa klas. Należy ją przekazać do `lime_image.LimeImageExplainer().explain_instance` przy użyciu `partial`, jako `partial(predict_batch, <model>)`, gdzie modelem w naszym wypadku będą sieci neuronowe. Przykłady użycia są zawarte w tym notebooku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce787c-88d0-4e92-b50f-2ca04bb15b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_batch(model, images):\n",
    "    model.eval()\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]) \n",
    "    ])   \n",
    "    \n",
    "    model.eval()\n",
    "    batch = torch.stack(tuple(transformer(i) for i in images), dim=0)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    logits = model(batch)\n",
    "    probas = torch.nn.functional.softmax(logits, dim=1)\n",
    "    return probas.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c176b5c-d9e8-4ad7-a8e2-d866f53486ad",
   "metadata": {},
   "source": [
    "Funkcja, która przekształca obrazek w format akcepptowany na wejściu przez LIME. Przykłady użycia są zawarte w tym notebooku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6afd319-8dae-4dfc-ab6d-0a1f2c691195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lime_transformer(image):\n",
    "    transformer = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.CenterCrop(224)\n",
    "    ])\n",
    "    return np.array(transformer(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e7311d-5f95-4ce5-a648-c2b5b54326ae",
   "metadata": {},
   "source": [
    "LIME jest głównie wykorzystywane do **wyjaśniania** predykcji tzw. czarnych skrzynek, czyli modeli nieinterpretowalnych. Idealnymi kandydatami są Głębokie Sieci Neuronowe, dlatego spróbujemy wyjaśnić niektóre predykcje gotowych modeli."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bedffa-0281-4d20-b150-89bedab18697",
   "metadata": {},
   "source": [
    "# **Model Inception-v3 - przygotowanie danych**\n",
    "https://arxiv.org/abs/1512.00567"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7949f4-c433-457f-89f5-3591c38c980a",
   "metadata": {},
   "source": [
    "Plik `./data/imagenet_class_index.json` zawiera przypisanie klas obrazków do indeksów. Jest to istotne, ponieważ zwracane wyniki (np. wartości funkcji logit na wyjściu sieci neuronowych) wykorzystują to, zwracając wyniki w zadanej kolejności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b81c48d-3563-4916-8eb9-e42c62d9a289",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/imagenet_class_index.json\") as f:\n",
    "    content = json.load(f)\n",
    "    index_to_label = {\n",
    "        int(index): data[1]\n",
    "        for index, data in content.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b741dd90-a10b-47ae-96e4-d4e95e92b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_classify = get_image(\"./data/dogs.png\")\n",
    "plt.imshow(image_to_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5c56d7-eac1-47b5-979b-790f44b1a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = image_to_tensor(image_to_classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ce147-9901-4934-bc6f-2755a443080c",
   "metadata": {},
   "source": [
    "### **Załadowanie pretrenowanego modelu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7ebdd-9f96-4d8a-8420-d218333ddfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_v3 = models.inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa318e-9421-4afc-bdef-159300e4f014",
   "metadata": {},
   "source": [
    "### **Predykcja**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b6fe0-04e9-4d04-8857-61127a22c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_v3.eval()\n",
    "logits = inception_v3(img_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4d438a-9705-4759-8408-41af1ae444b7",
   "metadata": {},
   "source": [
    "Zwróć uwagę, że model zwraca wartości funkcji logit, a nie prawdopodobieństwa klas, dlatego wyniki trzeba przetworzyć (np. przy użyciu funkcji softmax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a33a6-b82e-4817-9c82-1d894b34fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = torch.nn.functional.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9af3ab-3646-415d-94ef-53911b312556",
   "metadata": {},
   "source": [
    "Sprawdźmy N najbardziej prawdopodobnych klas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c37f065-a95e-43e5-ab2c-ab2026c4586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_LABELS = 15\n",
    "\n",
    "probas_top = probas.topk(TOP_N_LABELS)\n",
    "top_probas = probas_top[0][0].detach().numpy()\n",
    "top_labels = probas_top[1][0].detach().numpy()\n",
    "for proba, label in zip(top_probas, top_labels):\n",
    "    print(f\"Class: {index_to_label[label]:<30} | Probability: {proba:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038befd7",
   "metadata": {},
   "source": [
    "### **Teraz możemy te funkcje zebrać razem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01638bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_probabilities(image, model):\n",
    "    img_tensor = image_to_tensor(image)\n",
    "    model.eval()\n",
    "    logits = model(img_tensor)\n",
    "    probas = torch.nn.functional.softmax(logits, dim=1)\n",
    "    \n",
    "    TOP_N_LABELS = 15\n",
    "\n",
    "    probas_top = probas.topk(TOP_N_LABELS)\n",
    "    top_probas = probas_top[0][0].detach().numpy()\n",
    "    top_labels = probas_top[1][0].detach().numpy()\n",
    "    for proba, label in zip(top_probas, top_labels):\n",
    "        print(f\"Class: {index_to_label[label]:<30} | Probability: {proba:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42dc08b",
   "metadata": {},
   "source": [
    "### **I sprawdzić jak ta predykcja wygląda dla innego obrazka**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ac42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_image = get_image(\"./data/cat_mouse.jpeg\")\n",
    "plt.imshow(exercise_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1a271c",
   "metadata": {},
   "source": [
    "## **Zadanie: sprawdź jak będzie wyglądała predykcja dla powyższego obrazka**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e618fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_prediction_probabilities(here_insert_image, here_insert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76da836-1f34-4d01-a7b7-f008c08ad608",
   "metadata": {},
   "source": [
    "# **Model Inception-v3 - wyjaśnienie**\n",
    "\n",
    "Chcemy wiedzieć dlaczego klasa `Bernese_mountain_dog` została uznana przez sieć neuronową za najbardziej prawdopodobną (to znaczy - które piksele obrazka o tym zadecydowały). W tym celu właśnie wykorzystamy LIME.\n",
    "\n",
    "W jaki sposób działa LIME na obrazkach?\n",
    "1. Na wejściu wymagany jest oryginalny obrazek.\n",
    "2. Wejściowy obrazek jest delikatnie przekształcany wiele razy, dzięki czemu otrzymujemy wiele podobnych (ale nie takich samych!) obrazków.\n",
    "3. Dodatkowo na wejście musimy podać funkcję, która każdemu takiemu przekształceniu nada prawdopodobieństwo przynależności do danej klasy. Jest to wymagane ponieważ LIME jest niezależny od żadnych narzędzi i modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97c5c5-defa-4a35-90a2-f184701c195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b9a420-091c-4827-89f7-c64031341e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer.explain_instance(\n",
    "    image=lime_transformer(image_to_classify), \n",
    "    classifier_fn=partial(predict_batch, inception_v3),\n",
    "    top_labels=5,\n",
    "    num_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96604262",
   "metadata": {},
   "source": [
    "Mając te dane możemy teraz sprawdzić które kategorie są najbardziej prawdopodobne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab69d9-20e8-4e97-9a05-f88006eb6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in explanation.top_labels:\n",
    "    print(index_to_label[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e28a36-8c7d-45a4-aeff-253b4caf99cb",
   "metadata": {},
   "source": [
    "Zobaczmy co wpłynęło na wybranie `Bernese_mountain_dog` jako najbardziej prawdopodobnej klasy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28684493-4b2e-4cbc-8f79-bc14285eb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = explanation.get_image_and_mask(\n",
    "    label=explanation.top_labels[0],\n",
    "    positive_only=False,\n",
    "    negative_only=False,\n",
    "    num_features=10,\n",
    "    hide_rest=False)\n",
    "boundaries = mark_boundaries(image, mask)\n",
    "plt.imshow(boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f265f9",
   "metadata": {},
   "source": [
    "## **Zadanie: zmień wartość NUM_FEATURES i zaobserwuj jak zmienia się mapowanie**\n",
    "NUM_FEATURES najlepiej zmieniać w zakresie 1:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67463e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 10\n",
    "\n",
    "image, mask = explanation.get_image_and_mask(\n",
    "    label=explanation.top_labels[0],\n",
    "    positive_only=False,\n",
    "    negative_only=False,\n",
    "    num_features=NUM_FEATURES,\n",
    "    hide_rest=False)\n",
    "boundaries = mark_boundaries(image, mask)\n",
    "plt.imshow(boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e9ae1b",
   "metadata": {},
   "source": [
    "Zielone fragmenty oznaczają \"superpiksele\", które pozytywnie wpływają na predykowaną klasę. Czerwone fragmenty wpływają negatywnie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a0d70b",
   "metadata": {},
   "source": [
    "## **Zadanie-pytanie: co to właściwie jest superpiksel?**\n",
    "## **Zadanie-pytanie: czy jeden superpiksel ma odzwierciedlenie w jednym pikselu z obrazka?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6984440-3839-47e0-a8b0-087936a9d690",
   "metadata": {},
   "source": [
    "Zobaczmy jak to się prezentuje dla drugiej najbardziej prawdopodobnej klasy, czyli `EntleBucher`, która jednak otrzymała jedyne 3.8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776ba38-73fd-4781-83f4-0a628f48f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = explanation.get_image_and_mask(\n",
    "    label=explanation.top_labels[1],\n",
    "    positive_only=False,\n",
    "    negative_only=False,\n",
    "    num_features=10,\n",
    "    hide_rest=False)\n",
    "boundaries = mark_boundaries(image, mask)\n",
    "plt.imshow(boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09658779",
   "metadata": {},
   "source": [
    "# **Model Inception-v3 - porównanie z AlexNet**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7c3f81-12fd-4041-9911-ca7d52d6db69",
   "metadata": {},
   "source": [
    "Przetestujmy działanie na innym modelu - `AlexNet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30fd94b-fa32-4967-bf56-5632df362a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d27bac-6b56-4a08-9c9e-2fb0ef085654",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_alexnet = explainer.explain_instance(\n",
    "    image=lime_transformer(image_to_classify), \n",
    "    classifier_fn=partial(predict_batch, alexnet),\n",
    "    top_labels=5,\n",
    "    num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2df4b4-6f1f-47c9-a007-921980a9b75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_alex, index_inception in zip(explanation_alexnet.top_labels, explanation.top_labels):\n",
    "    print(f\"{index_to_label[index_alex]:30} | {index_to_label[index_inception]:30}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e558ab4-cd08-4961-9af4-505dba19ba10",
   "metadata": {},
   "source": [
    "Jak widać, klasy nieco się różnią, ale TOP 1 pozostaje takie samo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8377fb8-8d31-408e-b4c6-2e134a6b9851",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = explanation_alexnet.get_image_and_mask(\n",
    "    label=explanation_alexnet.top_labels[0],\n",
    "    positive_only=False,\n",
    "    negative_only=False,\n",
    "    num_features=10,\n",
    "    hide_rest=False)\n",
    "boundaries = mark_boundaries(image, mask)\n",
    "plt.imshow(boundaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab31d010-40d1-42af-bc9a-aa0e1be88b31",
   "metadata": {},
   "source": [
    "Wyjaśnienie dla `AlexNet` jak się można było spodziewać - też się różni, jednak w dalszym ciągu do klasyfikacji psa istotny jest... pies :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e31148",
   "metadata": {},
   "source": [
    "## **Zadanie: porównaj predykcje obrazka dla modeli inception_v3 oraz alexnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34292425",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"inception_v3\")\n",
    "# get_prediction_probabilities(image_to_classify, here_insert_model)\n",
    "print()\n",
    "print(\"alexnet\")\n",
    "# get_prediction_probabilities(image_to_classify, here_insert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23405c20-8dad-494f-acfb-406f5cf7cd13",
   "metadata": {},
   "source": [
    "# **Zadanie domowe**\n",
    "W folderze `data` znajduje się zdjęcie amfibii:\n",
    "![title](data/amfibia.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ee430a-ddab-4135-8a6c-3110928cce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "amphibious_vehicle = get_image(\"./data/amfibia.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afadd91b-8dde-4bb3-8800-d361aad152f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_amhibious_vehicle = explainer.explain_instance(\n",
    "    image=lime_transformer(amphibious_vehicle), \n",
    "    classifier_fn=partial(predict_batch, inception_v3),\n",
    "    top_labels=5,\n",
    "    num_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7525f34b-0cd5-4755-bfe0-2e162b9cc9c2",
   "metadata": {},
   "source": [
    "Model `inception_v3` jak i jego wyjaśnienie rzeczywiście sugerują amfibię jako najbardziej prawdopodobną klasę:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc2c84d-a4de-4eeb-8b16-1c4b651b425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in explanation_amhibious_vehicle.top_labels:\n",
    "    print(index_to_label[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d422d2-97fb-45ca-a30e-76549519a530",
   "metadata": {},
   "source": [
    "### **Co trzeba zrobić?**\n",
    "\n",
    "1. Użyj **trzech** różnych sieci neuronowych (możesz również użyć wcześniej poznane `inecption_v3`) do wygenerowania wyjaśnień. (skorzystaj z modułu torchvision: https://pytorch.org/vision/stable/models.html - w ten sposób importowaliśmy `inception_v3` ;) )\n",
    "2. Zmodyfikuj oryginalny obrazek w taki sposób, żeby najbardziej prawdopodobną klasą dla każdej z tych sieci **nie była** amfibia a jakiś inny pojazd (np. samochód). W tym celu możesz \"zasłonić\" czarnym kwadratem (wartość 0 w macierzy reprezentującej obraz) obszary istotne przy klasyfikacji.\n",
    "3. Ponownie zmodyfikuj oryginalny obraz, ale tym razem zaszumiając go w losowy sposób (przykładowa implementacja: https://www.geeksforgeeks.org/add-a-salt-and-pepper-noise-to-an-image-with-python/). Czy najbardziej prawdopodobna klasa zmienia się wraz ze zmianą szumu? Przetestuj dla każdego z modeli."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
